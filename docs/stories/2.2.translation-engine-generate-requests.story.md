# Story 2.2: Translation Engine for Generate Requests

## Status
Draft

## Story
**As a** developer,
**I want** to translate Ollama generate requests to OpenAI chat completion format,
**so that** the requests can be processed by OpenAI backends.

## Acceptance Criteria
1. Translation function converts Ollama prompt to OpenAI messages format
2. Ollama options (temperature, top_p, etc.) are mapped to OpenAI parameters
3. Model name is preserved in the OpenAI request
4. Stream parameter is correctly passed through
5. Translation handles missing optional parameters with defaults
6. Unit tests cover all parameter mappings and edge cases

## Tasks / Subtasks
- [ ] Create translation function for generate requests (AC: 1, 3, 4)
  - [ ] Create translate_generate_request() in src/services/translator.py
  - [ ] Convert Ollama prompt to OpenAI messages array format
  - [ ] Map model name directly to OpenAI model parameter
  - [ ] Pass through stream parameter
- [ ] Map Ollama options to OpenAI parameters (AC: 2, 5)
  - [ ] Map temperature (direct mapping)
  - [ ] Map top_p (direct mapping)
  - [ ] Map max_tokens from num_predict
  - [ ] Map stop sequences if provided
  - [ ] Handle missing parameters with sensible defaults
- [ ] Implement parameter validation and defaults (AC: 5)
  - [ ] Define default values for optional parameters
  - [ ] Validate parameter ranges (e.g., temperature 0-2)
  - [ ] Document parameter mapping table
- [ ] Unit tests for translation logic (AC: 6)
  - [ ] Test basic prompt to messages conversion
  - [ ] Test all parameter mappings
  - [ ] Test default value handling
  - [ ] Test edge cases (empty prompt, invalid parameters)

## Dev Notes

### Previous Story Insights
Story 2.1 defines the Ollama generate request/response models that this translation engine will consume.

### Data Models
[Source: architecture/data-models.md#ollamageneraterequest]
- **OllamaGenerateRequest**: 
  - model: str - The model identifier
  - prompt: str - Text prompt to generate from
  - stream: bool - Whether to stream response
  - options: Dict[str, Any] - Additional parameters

OpenAI ChatCompletion format needed:
```python
{
    "model": "gpt-4",
    "messages": [{"role": "user", "content": "prompt text"}],
    "stream": false,
    "temperature": 0.7,
    "top_p": 1.0,
    "max_tokens": None
}
```

### API Specifications
[Source: architecture/ollama-api-implementation.md#post-apigenerate]
Ollama options that need mapping:
- temperature → temperature (direct)
- top_p → top_p (direct)
- num_predict → max_tokens
- stop → stop (array of strings)
- seed → seed (if supported)
- num_ctx → (context window, may not map)

### Component Specifications
[Source: architecture/components.md#translation-engine]
Translation Engine responsibilities:
- Convert between Ollama and OpenAI formats
- Maintain parameter fidelity
- Handle missing parameters gracefully
- Preserve model names without modification

### File Locations
[Source: architecture/source-tree.md]
- Translation service: `src/services/translator.py`
- Unit tests: `tests/unit/test_translator.py`
- Models used: `src/models/ollama.py`, `src/models/openai.py`

### Testing Requirements
Parameter mapping test cases:
- Basic prompt with no options
- Full options object with all parameters
- Partial options with some parameters
- Invalid parameter values
- Empty/null prompt handling
- Very long prompts

### Technical Constraints
[Source: architecture/tech-stack.md]
- Use OpenAI Python SDK 1.10.0 types
- Maintain async compatibility
- Type hints required for all functions
- No hardcoded parameter values

### Testing
#### Test Standards
[Source: architecture/coding-standards.md]
- Test file: `tests/unit/test_translator.py`
- Use pytest with parametrized tests for parameter combinations
- Mock OpenAI client interactions
- Test both successful translations and error cases

#### Specific Testing Requirements
- Parametrized tests for all option mappings
- Edge case tests for boundary values
- Test default value application
- Verify type conversions (e.g., string to float)
- Test prompt escaping/sanitization if needed

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-23 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results
*Results from QA Agent review will be populated here*