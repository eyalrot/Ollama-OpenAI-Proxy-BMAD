# Story 3.3: Implement /api/embeddings Endpoints with Translation Engine

**⚠️ CRITICAL: All Python activities including running unit tests, integration tests, and any Python commands MUST be executed inside the virtual environment (venv). Always activate the virtual environment first with `source venv/bin/activate` before running any Python-related commands.**

## Status
Draft

## Story
**As an** Ollama SDK user,
**I want** to generate embeddings using client.embeddings() method with seamless translation between Ollama and OpenAI formats,
**so that** I can create vector representations of text for semantic search and similarity operations.

## Acceptance Criteria
1. POST /api/embeddings endpoint is implemented and working
2. POST /api/embed endpoint aliases to same functionality  
3. Endpoint accepts model and prompt parameters in Ollama format
4. Request is translated to OpenAI embeddings format correctly
5. Response returns embedding array in Ollama format
6. Both endpoints return identical responses
7. Ollama prompt is converted to OpenAI input format
8. Model name is correctly mapped
9. OpenAI embedding response is extracted to array format
10. Response contains only the embedding array as expected by Ollama
11. High-dimensional embeddings are handled without truncation
12. Unit tests verify dimension preservation

## Tasks / Subtasks
- [ ] Review API compliance requirements (AC: 3, 4, 7)
  - [ ] Read architecture/api-compliance-checklist.md
  - [ ] Check architecture/ollama-api-implementation.md for /api/embed details
  - [ ] Review architecture/ollama-api-analysis-chat-embeddings.md for embeddings specifics
  - [ ] Load Ollama OpenAPI specification for embeddings endpoint
- [ ] Create Ollama embeddings request/response models (AC: 3)
  - [ ] Define OllamaEmbeddingsRequest in src/models/ollama.py
  - [ ] Define OllamaEmbeddingsResponse in src/models/ollama.py  
  - [ ] Add validation for required fields (model, prompt)
  - [ ] Ensure models match OpenAPI specification exactly
- [ ] Implement /api/embeddings and /api/embed routers (AC: 1, 2, 6)
  - [ ] Create src/routers/embeddings.py
  - [ ] Add POST /api/embeddings endpoint
  - [ ] Add POST /api/embed endpoint that routes to same handler
  - [ ] Add request validation using Pydantic models
  - [ ] Implement proper async handler
- [ ] Implement embeddings translation functions (AC: 4, 5, 7-11)
  - [ ] Create translate_embeddings_request() in src/services/translator.py
  - [ ] Convert Ollama prompt to OpenAI input format (prompt → input)
  - [ ] Map model names appropriately
  - [ ] Create translate_embeddings_response() for response conversion
  - [ ] Extract embedding array from OpenAI response format
  - [ ] Handle high-dimensional embeddings without truncation
  - [ ] Ensure response contains only embedding array field
- [ ] Unit tests for embeddings endpoints (AC: 1-12)
  - [ ] Test request validation with various inputs
  - [ ] Test model name validation
  - [ ] Test both endpoint paths return same response
  - [ ] Test embedding dimension preservation
  - [ ] Test high-dimensional vectors (1536, 3072, etc.)
  - [ ] Test error handling for invalid requests
  - [ ] Test empty/long prompts
  - [ ] Verify all unit tests are passing
- [ ] Integration tests with Ollama SDK (AC: 1-12)
  - [ ] Create tests/integration/test_ollama_sdk_embeddings.py
  - [ ] Test client.embeddings() against running server
  - [ ] Verify embedding vector dimensions match model
  - [ ] Test with different text lengths
  - [ ] Test dimension preservation for large embeddings
  - [ ] Test error scenarios
  - [ ] Verify both endpoints work identically
- [ ] API compliance validation (AC: 1-12)
  - [ ] Test with Ollama CLI
  - [ ] Test with Ollama SDK
  - [ ] Validate response format matches spec
  - [ ] Verify dimension preservation

## Dev Notes

### Previous Story Insights
From Story 3.1 (Chat Endpoint):
- Use existing error handling framework from src/ollama_openai_proxy/utils/errors.py
- Follow async patterns established in chat endpoint
- Reuse translation service patterns for consistency

### Data Models and Translation Mapping
[Source: architecture/ollama-api-implementation.md]
**OllamaEmbeddingsRequest**:
- model: str - Model identifier
- prompt: str - Text to embed

**Translation Mapping (Ollama → OpenAI)**:
- prompt → input (direct string mapping)
- model → model (preserve as-is)

**Response Format**:
```json
{
  "embedding": [0.1, 0.2, 0.3, ...]
}
```

### API Specifications
[Source: architecture/ollama-api-analysis-chat-embeddings.md]
- Single text input only (not array) in Ollama format
- Output dimensions vary by model (384, 768, 1024, 1536, etc.)
- Both /api/embeddings and /api/embed must work identically
- Response contains single "embedding" field with float array

### Component Specifications
[Source: architecture/source-tree.md]
- Router location: `src/routers/embeddings.py`
- Model definitions: `src/models/ollama.py` (add embeddings models)
- Translation logic: `src/services/translator.py` (add embeddings methods)
- Integration with: `src/services/openai_client.py`
- Error handling: `src/utils/errors.py`

### Testing Requirements
[Source: architecture/coding-standards.md]
- Unit tests must cover all validation scenarios
- Integration tests MUST test against running server instance
- Test with actual Ollama SDK, not mocked
- Verify exact response format matches Ollama spec

### Technical Constraints
[Source: architecture/tech-stack.md]
- Python 3.12 with FastAPI 0.109.0
- Use Pydantic 2.5.3 for data validation
- All route handlers must be async
- Reuse existing OpenAI SDK wrapper service

**Note:** This story merges the original Epic 3 stories 3.3 (Embeddings Endpoints) and 3.4 (Embeddings Translation Engine) as they are tightly coupled and should be implemented together. The translation logic is an integral part of the embeddings endpoint implementation.

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-23 | 1.0 | Initial story creation | Bob (Scrum Master) |
| 2025-01-23 | 1.1 | Merged Story 3.4 (Embeddings Translation Engine) | Bob (Scrum Master) |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results
*Results from QA Agent review will be populated here*