# Story 3.1: Implement /api/chat Endpoint with Translation Engine

**⚠️ CRITICAL: All Python activities including running unit tests, integration tests, and any Python commands MUST be executed inside the virtual environment (venv). Always activate the virtual environment first with `source venv/bin/activate` before running any Python-related commands.**

## Status
Completed

## Story
**As an** Ollama SDK user,
**I want** to have chat conversations using client.chat() method with seamless translation between Ollama and OpenAI formats,
**so that** I can build conversational AI applications that work with OpenAI-compatible backends.

## Acceptance Criteria
1. POST /api/chat endpoint is implemented with message history support
2. Endpoint accepts messages array with role and content
3. Request validation ensures message format is correct
4. Both streaming and non-streaming modes are supported
5. Response includes assistant message with proper format
6. System messages are properly handled if present
7. Ollama messages format maps directly to OpenAI format
8. Role mappings are preserved (user, assistant, system)
9. Message content is passed through without modification
10. Chat options are translated to OpenAI parameters
11. Translation handles multi-turn conversations correctly
12. Integration tests validate real Ollama SDK against running server

## Tasks / Subtasks
- [x] Review API compliance requirements (AC: 2, 3)
  - [x] Read architecture/api-compliance-checklist.md
  - [x] Check architecture/ollama-api-implementation.md for /api/chat details
  - [x] Review architecture/ollama-api-analysis-chat-embeddings.md for chat specifics
  - [x] Review architecture/epic-1-fix-guide.md for lessons learned
  - [x] Load Ollama OpenAPI specification for chat endpoint
- [x] Implement contract tests FIRST (TDD approach) (AC: 1-6) - SKIPPED per user request
  - [x] Create tests/contract/test_chat_contract.py - SKIPPED
  - [x] Test request format matches Ollama OpenAPI spec (messages array) - SKIPPED
  - [x] Test response format matches Ollama OpenAPI spec - SKIPPED
  - [x] Test streaming format compliance (newline-delimited JSON) - SKIPPED
  - [x] Test role handling (user, assistant, system) - SKIPPED
  - [x] Use validation tool: python tools/validate_against_openapi.py - SKIPPED
- [x] Create Ollama chat request/response models (AC: 2, 3)
  - [x] Define OllamaChatRequest in src/models/ollama.py
  - [x] Define OllamaChatResponse in src/models/ollama.py
  - [x] Add validation for messages array structure
  - [x] Add validation for role field (user/assistant/system)
  - [x] Add optional parameters (stream, options)
  - [x] Ensure models match OpenAPI specification exactly
- [x] Implement /api/chat router (AC: 1, 4)
  - [x] Create src/routers/chat.py
  - [x] Add POST /api/chat endpoint
  - [x] Add request validation using Pydantic models
  - [x] Handle both streaming and non-streaming modes
  - [x] Implement proper async handler
- [x] Implement chat translation functions (AC: 4, 5, 6, 7-11)
  - [x] Create translate_chat_request() in src/services/translator.py
  - [x] Convert Ollama messages array to OpenAI format (direct mapping)
  - [x] Map chat options to OpenAI parameters (temperature, top_p, etc.)
  - [x] Create translate_chat_response() for non-streaming responses
  - [x] Create translate_chat_stream_chunk() for streaming responses
  - [x] Handle message history translation for multi-turn conversations
  - [x] Ensure role mappings are preserved (user/assistant/system)
  - [x] Handle non-streaming responses as complete JSON
  - [x] Handle streaming responses as newline-delimited JSON
- [x] Unit tests for chat endpoint (AC: 1-6)
  - [x] Test request validation with various message formats
  - [x] Test single-turn conversations
  - [x] Test multi-turn conversations
  - [x] Test system message handling
  - [x] Test non-streaming response format
  - [x] Test streaming response format
  - [x] Test error handling for invalid requests
  - [x] Verify all unit tests are passing
- [x] Integration tests with Ollama SDK against running server (AC: 1-12)
  - [x] Create tests/integration/test_ollama_sdk_chat.py
  - [x] Set up test fixture to start actual server instance
  - [x] Test client.chat() with basic conversation against live server
  - [x] Test streaming chat responses with real-time validation
  - [x] Test multi-turn conversations with context preservation
  - [x] Test with system prompts and role handling
  - [x] Test parameter translation (temperature, top_p, max_tokens)
  - [x] Verify response format matches SDK expectations
  - [x] Test error scenarios with running server
  - [x] Performance test to ensure minimal translation overhead
- [x] API compliance validation (AC: 1-6)
  - [x] Run contract tests to verify compliance (skipped per user request)
  - [x] Test with Ollama CLI: ollama chat (tested via curl)
  - [x] Test with Ollama SDK (verified via integration tests)
  - [x] Validate using python tools/validate_against_openapi.py (manually verified response format)

## Dev Notes

### Previous Story Insights
From Story 2.7 (Error Handling):
- Comprehensive error handling framework implemented in src/ollama_openai_proxy/utils/errors.py
- Error mapping between Ollama and OpenAI formats established
- Use existing error handling patterns for chat endpoint errors

**Note:** This story merges the original Epic 3 stories 3.1 (Chat Endpoint) and 3.2 (Chat Translation Engine) as they are tightly coupled and should be implemented together. The translation logic is an integral part of the chat endpoint implementation.

### Data Models and Translation Mapping
[Source: architecture/data-models.md#ollamachatrequest]
- **OllamaChatRequest**: 
  - model: str - Model identifier (maps directly to OpenAI)
  - messages: List[Dict[str, str]] - Array of message objects with role and content
  - stream: bool - Whether to stream response (default: false)
  - options: Dict[str, Any] - Additional parameters like temperature, top_p

**Translation Mapping (Ollama → OpenAI):**
- messages array → messages array (direct mapping, same structure)
- role values → role values (user/assistant/system map directly)
- options.temperature → temperature
- options.top_p → top_p
- options.max_tokens → max_tokens
- options.stop → stop
- model → model (preserve as-is)

[Source: architecture/ollama-api-implementation.md#post-apichat]
Required request format:
```json
{
  "model": "llama2",
  "messages": [
    {"role": "user", "content": "Hello!"},
    {"role": "assistant", "content": "Hi there! How can I help you?"},
    {"role": "user", "content": "Tell me a joke"}
  ],
  "stream": false
}
```

Non-streaming response format:
```json
{
  "model": "llama2",
  "created_at": "2023-08-04T19:56:02.647Z",
  "message": {
    "role": "assistant",
    "content": "Why did the scarecrow win an award? He was outstanding in his field!"
  },
  "done": true,
  "total_duration": 5589157167,
  "load_duration": 3013701500
}
```

Streaming response format (newline-delimited JSON):
```
{"model":"llama2","created_at":"2023-08-04T19:56:02.647Z","message":{"role":"assistant","content":"Why"},"done":false}
{"model":"llama2","created_at":"2023-08-04T19:56:02.647Z","message":{"role":"assistant","content":" did"},"done":false}
{"model":"llama2","created_at":"2023-08-04T19:56:02.647Z","message":{"role":"assistant","content":""},"done":true}
```

### API Specifications
[Source: architecture/ollama-api-implementation.md#critical-api-compliance-guidelines]
- Must validate against official Ollama API specification
- Use RFC3339 timestamp format with timezone offset
- Streaming format must be newline-delimited JSON, not SSE or arrays
- Both streaming and non-streaming modes required
- Direct mapping to OpenAI ChatCompletionRequest format

[Source: architecture/api-compliance-checklist.md]
⚠️ **CRITICAL**: Before implementing, review the API Compliance Checklist
- Chat endpoint has direct mapping to OpenAI format
- Messages array structure is identical
- Role values map directly (user, assistant, system)
- Always implement contract tests FIRST (TDD approach)
- Use the Postman collection: architecture/Ollama REST API.postman_collection.json
- Validate with: python tools/validate_against_openapi.py

### Component Specifications
[Source: architecture/source-tree.md]
- Router location: `src/routers/chat.py`
- Model definitions: `src/models/ollama.py`
- Translation logic: `src/services/translator.py` (add chat translation methods)
- Integration with: `src/services/openai_client.py`
- Error handling: `src/utils/errors.py`
- Integration tests: `tests/integration/test_ollama_sdk_chat.py`

### File Locations
[Source: architecture/source-tree.md]
- Main router: `src/routers/chat.py`
- Models: `src/models/ollama.py` (add chat models)
- Unit tests: `tests/unit/test_routers.py` (add chat tests)
- Integration tests: `tests/integration/test_ollama_sdk_chat.py`
- Contract tests: `tests/contract/test_chat_contract.py`

### Testing Requirements
[Source: architecture/coding-standards.md#core-standards]
- Test organization: `tests/{unit,integration,contract}/test_*.py`
- All route handlers must be async
- Type hints required for all functions
- Unit tests must cover request validation, response formats, error handling
- Integration tests MUST test against running server instance
- Contract tests for API compliance

**Critical Integration Test Requirements:**
- Tests must use actual Ollama SDK (not mocked)
- Server must be running during tests (use test fixtures)
- Validate end-to-end flow from SDK → Server → OpenAI → Server → SDK
- Measure translation overhead and performance impact

[Source: architecture/test-strategy-and-standards.md#contract-tests]
- Contract tests are CRITICAL for API compliance
- Must validate exact request/response formats
- Run before implementing endpoint (TDD)
- Use OpenAPI specification as source of truth

### Technical Constraints
[Source: architecture/tech-stack.md]
- Python 3.12 with FastAPI 0.109.0
- Use Pydantic 2.5.3 for data validation
- All route handlers must be async
- Virtual environment required for local development
- Must use existing OpenAI SDK wrapper service
- Use existing translation patterns from generate endpoint

### Testing
#### Test Standards
[Source: architecture/coding-standards.md]
- Test files in `tests/unit/`, `tests/integration/`, and `tests/contract/`
- Use pytest framework with pytest-asyncio for async testing
- All endpoint tests must be async
- Test both success and error cases
- Mock external dependencies (OpenAI service)
- 90% test coverage required

#### Specific Testing Requirements
- **Contract tests FIRST**: Must pass before implementing endpoint
  - Create tests/contract/test_chat_contract.py
  - Validate request/response against OpenAPI spec
  - Use tools/validate_against_openapi.py
- Unit tests: Request validation, response formatting, error handling
- Integration tests: End-to-end chat functionality with SDK against live server
  - MUST test real SDK → running server → OpenAI backend flow
  - Use pytest fixtures to start/stop server for tests
  - Validate actual SDK compatibility, not mocked behavior
- Test both streaming and non-streaming modes
- Test single and multi-turn conversations
- Test system message handling
- Verify timestamp formats and response structure
- Test with real Ollama CLI and SDK to ensure compatibility

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-23 | 1.0 | Initial story creation | Bob (Scrum Master) |
| 2025-01-23 | 1.1 | Merged Story 3.2 (Chat Translation Engine) and added live server integration tests | Bob (Scrum Master) |
| 2025-01-23 | 1.2 | Story approved and ready for development | Bob (Scrum Master) |
| 2025-01-23 | 1.3 | Story completed with all tasks and subtasks done | James (Developer) |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
claude-3-5-sonnet-20241022

### Debug Log References
- Started implementation of Story 3.1
- Reviewed all API compliance documentation
- Chat endpoint format: messages array with role/content, streaming as newline-delimited JSON
- Created OllamaChatMessage, OllamaChatRequest, OllamaChatResponse, OllamaChatStreamChunk models
- Created chat router with streaming and non-streaming support
- Registered chat router in main.py
- Implemented chat translation functions with direct message mapping and options translation
- Created comprehensive unit tests for chat endpoint
- Fixed async test decorators (@pytest.mark.asyncio)
- Fixed model imports in __init__.py
- Created integration tests with Ollama SDK against running server
- Fixed streaming duplicate 'stream' parameter issue in translation
- All unit tests passing (57 total)
- All integration tests passing (12 chat-specific tests)
- API compliance verified with curl and response format validation

### Completion Notes List
1. Chat endpoint fully implemented with both streaming and non-streaming support
2. Direct message mapping between Ollama and OpenAI formats (no transformation needed)
3. All acceptance criteria met and tested
4. Integration tests confirm real Ollama SDK compatibility
5. Fixed streaming issue where 'stream' parameter was duplicated in kwargs
6. Added critical warning about using venv for all Python activities
7. Contract tests were skipped per user request but functionality verified through integration tests

### File List
- Modified: src/ollama_openai_proxy/models/ollama.py (added chat models)
- Created: tests/contract/__init__.py (skipped implementation per user request)
- Created: src/ollama_openai_proxy/routes/chat.py
- Modified: src/ollama_openai_proxy/main.py (added chat router)
- Modified: src/ollama_openai_proxy/services/enhanced_translation_service.py (added chat translation methods, fixed streaming)
- Created: tests/unit/test_chat_endpoint.py
- Modified: src/ollama_openai_proxy/models/__init__.py (exported chat models)
- Created: tests/integration/test_ollama_sdk_chat.py
- Modified: docs/prd/epic-3-advanced-features-distribution.md (added venv warning)
- Modified: docs/stories/3.1.implement-api-chat-endpoint.story.md (tracked progress and added venv warning)

## QA Results
*Results from QA Agent review will be populated here*